{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da2cffa-159b-4212-bd7a-f8c8a10a2415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:08:23.796925Z",
     "iopub.status.busy": "2025-09-28T22:08:23.794909Z",
     "iopub.status.idle": "2025-09-28T22:09:49.199812Z",
     "shell.execute_reply": "2025-09-28T22:09:49.198301Z",
     "shell.execute_reply.started": "2025-09-28T22:08:23.796925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\med\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from langchain_core.documents import Document\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.messages import HumanMessage\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9398a1fd-d568-4a91-95cc-b627712428a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:09:49.211416Z",
     "iopub.status.busy": "2025-09-28T22:09:49.209731Z",
     "iopub.status.idle": "2025-09-28T22:09:49.248543Z",
     "shell.execute_reply": "2025-09-28T22:09:49.246529Z",
     "shell.execute_reply.started": "2025-09-28T22:09:49.211416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taking the key to connect with OpenAI to use them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a338253-02db-41f6-bcc3-429be3149afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:09:49.304370Z",
     "iopub.status.busy": "2025-09-28T22:09:49.296722Z",
     "iopub.status.idle": "2025-09-28T22:09:49.352602Z",
     "shell.execute_reply": "2025-09-28T22:09:49.347530Z",
     "shell.execute_reply.started": "2025-09-28T22:09:49.304370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988499db-d066-4b0d-87f2-d18fbce81e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:09:49.378314Z",
     "iopub.status.busy": "2025-09-28T22:09:49.376797Z",
     "iopub.status.idle": "2025-09-28T22:09:49.396785Z",
     "shell.execute_reply": "2025-09-28T22:09:49.393551Z",
     "shell.execute_reply.started": "2025-09-28T22:09:49.378314Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initializing the Model becuase as we need to use the model so key is loaded now we enter in the room and selected the mode which is\n",
    "#CLIP and now we are initialing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46d6971-3e4f-4677-8ed2-b588c18ddb86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:09:49.420894Z",
     "iopub.status.busy": "2025-09-28T22:09:49.412807Z",
     "iopub.status.idle": "2025-09-28T22:10:01.098431Z",
     "shell.execute_reply": "2025-09-28T22:10:01.094535Z",
     "shell.execute_reply.started": "2025-09-28T22:09:49.420894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Fetching 1 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_preprocess = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5c5031-4baf-4658-a807-9d9610cec0c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.122131Z",
     "iopub.status.busy": "2025-09-28T22:10:01.120112Z",
     "iopub.status.idle": "2025-09-28T22:10:01.142874Z",
     "shell.execute_reply": "2025-09-28T22:10:01.140853Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.122131Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now the next step is to embedd the images and text for that matter we need to make two functions which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8023695-697c-4608-b0fb-3f6e27e5f50e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.188733Z",
     "iopub.status.busy": "2025-09-28T22:10:01.184700Z",
     "iopub.status.idle": "2025-09-28T22:10:01.211930Z",
     "shell.execute_reply": "2025-09-28T22:10:01.209911Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.188733Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_image(image_data):\n",
    "    if isinstance(image_data , str):\n",
    "        image =Image.open(image_data).convert(\"RGB\")\n",
    "    else:\n",
    "        image = image_data\n",
    "\n",
    "    inputs = clip_preprocess(images = image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_image_features(**inputs)\n",
    "        features = features / features.norm(dim= -1 , keepdim=True)\n",
    "        return features.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa095a6-c0fa-4baa-8a3e-0ade26bea001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.226925Z",
     "iopub.status.busy": "2025-09-28T22:10:01.224906Z",
     "iopub.status.idle": "2025-09-28T22:10:01.242058Z",
     "shell.execute_reply": "2025-09-28T22:10:01.240042Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.226925Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets do embedding for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d16dbc0b-652d-4c5b-887d-c755b11fc61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.259744Z",
     "iopub.status.busy": "2025-09-28T22:10:01.257724Z",
     "iopub.status.idle": "2025-09-28T22:10:01.283883Z",
     "shell.execute_reply": "2025-09-28T22:10:01.277409Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.259744Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_text(text):\n",
    "    inputs = clip_preprocess(text=text, return_tensors=\"pt\" , padding=True, truncation=True, max_length=77)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_text_features(**inputs)\n",
    "        features = features / features.norm(dim= -1 , keepdim=True)\n",
    "        return features.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b57d440-bc2d-45d8-8595-57d10c666001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.293480Z",
     "iopub.status.busy": "2025-09-28T22:10:01.293480Z",
     "iopub.status.idle": "2025-09-28T22:10:01.309657Z",
     "shell.execute_reply": "2025-09-28T22:10:01.307640Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.293480Z"
    }
   },
   "outputs": [],
   "source": [
    "#Embedding is done lets read the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e6d09dc-c154-4072-b0b4-4b8a3a876819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.325883Z",
     "iopub.status.busy": "2025-09-28T22:10:01.325883Z",
     "iopub.status.idle": "2025-09-28T22:10:01.680814Z",
     "shell.execute_reply": "2025-09-28T22:10:01.680814Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.325883Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf_path  = \"multimodal_sample.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "all_docs =[]\n",
    "all_embeddings = []\n",
    "image_data_store = {}\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500 , chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9874c959-77f4-4125-ad84-19d620491635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.699856Z",
     "iopub.status.busy": "2025-09-28T22:10:01.692919Z",
     "iopub.status.idle": "2025-09-28T22:10:01.724973Z",
     "shell.execute_reply": "2025-09-28T22:10:01.722962Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.699856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document('multimodal_sample.pdf')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "480678b6-649b-48fe-bc57-57bc0aa692b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:01.744708Z",
     "iopub.status.busy": "2025-09-28T22:10:01.742951Z",
     "iopub.status.idle": "2025-09-28T22:10:04.435939Z",
     "shell.execute_reply": "2025-09-28T22:10:04.435939Z",
     "shell.execute_reply.started": "2025-09-28T22:10:01.744708Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, page in enumerate(doc):\n",
    "    #This is for the text\n",
    "    text = page.get_text()\n",
    "    if text.strip():\n",
    "        temp_doc = Document(page_content=text , metadata={\"page\":i , \"type\":\"text\"})\n",
    "        text_chunk = splitter.split_documents([temp_doc])\n",
    "\n",
    "        for chunk in text_chunk:\n",
    "            embedding = embed_text(chunk.page_content)\n",
    "            all_embeddings.append(embedding)\n",
    "            all_docs.append(chunk)\n",
    "    #This is for the image\n",
    "    ##Three major steps will be taken \n",
    "    #-> Convert PDF to PIL image\n",
    "    #-> Store as a base64 string which is an text version of images\n",
    "    #-> CLIP embedding, CLIP is a pre trained model from openAI, also available on Hugging Face\n",
    "\n",
    "    #First step of converting the pdf to PIL image format\n",
    "    for img_index , img in enumerate(page.get_images(full=True)):\n",
    "        try:\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            pil_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "\n",
    "            image_id = f\"page_{i}_img_{img_index}\"\n",
    "            \n",
    "      #-> Store as a base64 string which is an text version of images      \n",
    "\n",
    "            buffered =io.BytesIO()\n",
    "            pil_image.save(buffered , format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "            image_data_store[image_id] = img_base64\n",
    "            \n",
    "      #-> CLIP embedding, CLIP is a pre trained model from openAI, also available on Hugging Face          \n",
    "\n",
    "            embedding = embed_image(pil_image)\n",
    "            all_embeddings.append(embedding)\n",
    "\n",
    "    #Lets create a document\n",
    "            image_doc = Document(page_content=f\"[Image: {image_id}]\", metadata={\"page\":i , \"type\":\"image\" , \"image_id\" : image_id})\n",
    "            all_docs.append(image_doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Error is for image {img_index} at the page {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9efc5b2-a9d6-4074-b797-348a1337fac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:04.452343Z",
     "iopub.status.busy": "2025-09-28T22:10:04.447819Z",
     "iopub.status.idle": "2025-09-28T22:10:04.512255Z",
     "shell.execute_reply": "2025-09-28T22:10:04.511075Z",
     "shell.execute_reply.started": "2025-09-28T22:10:04.452343Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-2.67243781e-03,  1.28300022e-02, -5.18314056e-02,  4.14879434e-02,\n",
       "        -2.33942084e-02, -7.55866105e-03, -3.67659107e-02,  1.19710736e-01,\n",
       "         8.52081031e-02,  2.05425802e-03, -1.11534707e-02, -1.29592177e-02,\n",
       "         5.25014549e-02, -3.65397707e-03,  4.76078540e-02,  1.58372894e-02,\n",
       "         2.03388296e-02,  4.35362384e-02, -3.29167210e-03,  2.03181319e-02,\n",
       "         1.88026356e-03, -4.23493981e-02,  5.44103794e-03,  3.70935835e-02,\n",
       "        -1.65622961e-02,  6.48646429e-03, -4.78012413e-02,  8.67478456e-03,\n",
       "         5.88859655e-02, -3.21394205e-02,  4.32440080e-02,  9.65300854e-03,\n",
       "        -4.47923737e-03, -1.94858033e-02, -3.63502391e-02, -1.23471869e-02,\n",
       "        -2.17928980e-02, -1.99016239e-02,  8.09619948e-02, -3.32986861e-02,\n",
       "        -2.38901377e-02, -3.96138951e-02, -1.27280178e-02,  3.50381061e-02,\n",
       "        -2.52217129e-02,  2.00031535e-03,  1.49660306e-02, -2.31976397e-02,\n",
       "        -6.86791241e-02, -5.25778392e-04, -2.22545750e-02, -1.04103824e-02,\n",
       "        -1.96115542e-02, -5.11167832e-02, -3.00412923e-02, -4.71472517e-02,\n",
       "        -6.60406873e-02, -6.53187092e-03,  4.47769649e-02,  5.17134694e-03,\n",
       "        -2.09416151e-02,  1.23682653e-03,  2.28888299e-02, -1.85612577e-03,\n",
       "        -7.21756974e-03,  7.72090480e-02, -4.45430763e-02,  1.07155964e-02,\n",
       "        -1.00543806e-02,  2.43769921e-02, -5.69796301e-02,  3.43469903e-02,\n",
       "        -4.38812114e-02, -4.87334654e-02,  1.07071567e-02, -4.02080826e-03,\n",
       "        -4.04055268e-02, -1.38860662e-02,  7.36657577e-03, -1.29189109e-02,\n",
       "         1.98347457e-02,  5.15974611e-02,  1.53137734e-02,  6.00985363e-02,\n",
       "         2.91914530e-02,  2.13117097e-02,  1.05796922e-02, -1.75736640e-02,\n",
       "        -1.27161639e-02,  1.49259567e-02, -3.67730744e-02,  2.80871857e-02,\n",
       "        -7.37118209e-03, -3.20464559e-02, -6.50109351e-02, -2.11241543e-02,\n",
       "         1.02155581e-02,  1.08291367e-02,  2.33738478e-02, -3.79536040e-02,\n",
       "        -2.52661150e-04,  1.23480204e-02,  4.79925470e-03,  1.14295806e-03,\n",
       "         1.29668489e-02, -1.79976448e-02, -6.43284991e-02, -2.44850069e-02,\n",
       "        -5.11865951e-02,  4.14219163e-02,  2.92939097e-02, -1.51848286e-01,\n",
       "         4.36054766e-02,  3.35990102e-03, -1.57337170e-02, -1.68261733e-02,\n",
       "        -4.11889143e-02, -4.19661961e-02,  3.85781676e-02,  2.93741710e-02,\n",
       "         1.88560672e-02,  6.75269216e-02, -7.35580409e-03,  8.21798667e-03,\n",
       "         4.07200009e-02,  1.03858486e-02, -2.17651073e-02,  5.34508154e-02,\n",
       "        -1.53584564e-02, -2.10202392e-02, -1.74071714e-02, -3.29134800e-02,\n",
       "         1.69049911e-02,  4.25002068e-01, -4.37945090e-02,  4.46007354e-03,\n",
       "         1.76204722e-02, -1.57659426e-02, -5.26641533e-02,  5.28488718e-02,\n",
       "         1.84012309e-03, -3.39380912e-02, -1.30729042e-02, -3.59011181e-02,\n",
       "         3.76179162e-03,  3.87275182e-02, -2.52379905e-02, -1.17168557e-02,\n",
       "        -1.85121149e-02, -1.07054822e-02,  6.98614307e-03,  4.01850641e-02,\n",
       "         6.46594018e-02, -4.49310057e-03, -4.05048281e-02, -6.70560449e-02,\n",
       "        -6.74298406e-02,  6.93297526e-03,  3.56784761e-02, -2.30639987e-02,\n",
       "         1.13911321e-02,  4.64889454e-03, -4.67327051e-03, -2.93388534e-02,\n",
       "         2.70005818e-02,  2.80503165e-02,  1.54878171e-02,  4.98289168e-02,\n",
       "         1.75894680e-03,  1.59470756e-02, -1.87687501e-02,  2.38400474e-02,\n",
       "        -3.52132879e-02, -5.26169129e-02,  2.41551585e-02, -3.68121453e-02,\n",
       "        -2.27651317e-02, -1.65995676e-02,  6.62984103e-02,  4.72906642e-02,\n",
       "        -3.74228060e-02,  4.02233638e-02, -4.16416526e-02,  5.67455310e-03,\n",
       "         6.06893599e-02, -2.65664719e-02,  4.06134054e-02,  3.00408546e-02,\n",
       "         7.32574891e-03,  7.61868153e-03,  4.46414314e-02,  7.99624063e-03,\n",
       "         3.42843235e-02,  3.69458906e-02, -3.14735956e-02,  5.91586754e-02,\n",
       "        -1.93830561e-02,  6.43222630e-02,  3.22228931e-02, -6.08227076e-03,\n",
       "        -3.56892357e-04,  9.86463297e-03, -1.57797188e-02,  3.34350131e-02,\n",
       "        -4.46308637e-03, -1.63690560e-03,  4.39812765e-02, -2.97543928e-02,\n",
       "        -5.51466309e-02, -1.35631561e-02, -4.74109128e-02, -1.53332660e-02,\n",
       "         1.75195727e-02, -3.07431202e-02, -6.16584830e-02, -1.85413205e-03,\n",
       "        -7.01816520e-03,  2.12449096e-02, -2.42548180e-03, -5.68779046e-03,\n",
       "         7.10657611e-02, -8.37229099e-03, -2.79168375e-02,  2.05669869e-02,\n",
       "         1.80451991e-03,  2.59759706e-02, -1.15978830e-02,  1.05833597e-02,\n",
       "         6.48899153e-02, -1.04813473e-02,  8.43651243e-04, -8.50323960e-03,\n",
       "        -5.45837581e-02, -5.02442382e-02, -2.42582131e-02, -4.58891578e-02,\n",
       "        -2.73674764e-02, -3.71860005e-02, -1.69388130e-02,  3.86053859e-03,\n",
       "        -1.51375157e-03,  2.32304018e-02, -8.20594467e-03, -5.83864923e-04,\n",
       "        -3.10663087e-03,  4.16650111e-03,  1.92136187e-02, -3.45781744e-02,\n",
       "         1.72270238e-02, -1.64893828e-02, -5.55123296e-03, -1.03297886e-02,\n",
       "         3.63707617e-02, -8.18509050e-03, -1.89423189e-03,  2.80163698e-02,\n",
       "        -5.14980741e-02,  7.25948885e-02, -2.09429469e-02, -2.51389295e-02,\n",
       "        -2.79843085e-03, -1.17756538e-02, -3.84837203e-02,  2.46885903e-02,\n",
       "        -7.74490135e-03, -2.22943556e-02,  4.15773466e-02,  7.26592541e-02,\n",
       "         4.90002297e-02, -4.25625257e-02, -3.42780054e-02,  1.13822669e-02,\n",
       "         1.28216213e-02,  3.65284011e-02, -7.14555085e-02,  2.35049613e-02,\n",
       "         2.21516900e-02,  1.25494720e-02,  3.66669856e-02, -7.28748133e-03,\n",
       "         2.29847860e-02, -1.54457456e-02,  1.78450195e-03, -1.90552715e-02,\n",
       "         4.36998950e-03, -7.02118687e-03,  1.12454370e-02, -8.95216037e-03,\n",
       "         3.34546901e-02,  4.76906858e-02, -8.17533433e-02, -2.05467623e-02,\n",
       "         1.26276221e-02,  2.46593524e-02, -2.34584510e-02,  2.30956469e-02,\n",
       "         4.73869592e-03, -4.06231619e-02, -5.14065754e-03, -5.11262706e-03,\n",
       "        -1.87988076e-02, -9.51300841e-03, -4.06609774e-02, -5.94677264e-03,\n",
       "        -1.70053896e-02,  1.50672980e-02,  2.66338661e-02,  5.69825852e-03,\n",
       "         1.17725134e-02,  5.24606928e-02,  1.03016486e-02, -1.11168018e-02,\n",
       "         4.26219821e-01,  9.18330159e-03, -2.24645231e-02,  2.56878648e-05,\n",
       "         2.53463648e-02,  1.10829400e-03,  1.99250896e-02, -1.99981239e-02,\n",
       "        -4.37211581e-02,  3.78218517e-02, -2.89321300e-02, -5.03922924e-02,\n",
       "        -1.59865208e-02, -7.98649807e-03, -6.10551797e-02, -5.79015985e-02,\n",
       "         3.64041775e-02,  1.32154450e-01,  2.63348632e-02, -1.76311156e-03,\n",
       "        -1.95033494e-02, -7.45864399e-03,  3.09366770e-02, -7.06169829e-02,\n",
       "        -2.92609371e-02,  3.19207087e-02, -4.12236666e-03, -1.22661958e-03,\n",
       "         1.29286083e-03,  1.08487941e-02,  3.70535553e-02,  2.48648580e-02,\n",
       "         5.92989698e-02, -1.38130346e-02, -2.59326268e-02,  1.89559571e-02,\n",
       "        -1.21582439e-02, -1.44583499e-02,  4.56414483e-02, -1.11835310e-02,\n",
       "        -2.17036251e-02, -1.99640617e-02, -3.57391089e-02, -5.62390685e-02,\n",
       "        -3.62789147e-02,  2.04106537e-03, -6.21686736e-03,  2.86481832e-03,\n",
       "         2.45198384e-02, -2.52743401e-02, -1.87304672e-02, -4.26104777e-02,\n",
       "        -7.79900923e-02,  3.04665584e-02,  2.10639779e-02,  7.06648603e-02,\n",
       "         1.94357615e-02,  6.74400404e-02, -3.53913903e-02,  1.65051427e-02,\n",
       "         3.67446174e-03,  1.81801654e-02,  3.24926451e-02,  7.36143291e-02,\n",
       "         2.41952129e-02, -5.57403415e-02,  5.82811646e-02, -4.75137345e-02,\n",
       "         1.36916758e-02, -4.21429053e-02,  5.79718687e-02, -1.29638417e-02,\n",
       "        -3.83988135e-02,  8.61266479e-02,  7.02567995e-02,  4.58454248e-03,\n",
       "        -2.20486857e-02,  3.03836670e-02,  2.21410803e-02, -1.06150641e-04,\n",
       "         2.45712735e-02,  4.81936336e-03,  8.94928575e-02,  4.47986573e-02,\n",
       "        -5.43402508e-02,  1.29984599e-02, -7.96516333e-03,  5.46421036e-02,\n",
       "         4.41767201e-02,  6.39594253e-03, -8.61339178e-03, -5.03848754e-02,\n",
       "        -1.96266491e-02, -7.09272698e-02, -3.81455012e-02,  2.60177925e-02,\n",
       "        -2.14515850e-02,  1.67374732e-03, -3.15811448e-02, -1.01632560e-02,\n",
       "         5.47311492e-02, -3.02973334e-02,  7.97360856e-03, -3.90923694e-02,\n",
       "        -1.47981243e-02, -1.64482910e-02, -1.83398090e-02, -4.25217859e-02,\n",
       "         5.81512190e-02, -6.97389543e-02, -5.11610843e-02, -5.93192987e-02,\n",
       "         2.87116133e-02, -3.98670323e-02, -1.55106736e-02, -6.82010641e-03,\n",
       "        -6.87440038e-02, -1.56712197e-02, -8.30477395e-04,  5.69928885e-02,\n",
       "         9.76889022e-03,  1.99994668e-02, -3.99629772e-02, -2.07549427e-03,\n",
       "         7.32861040e-03, -8.19090463e-04, -3.02243568e-02,  3.75215895e-02,\n",
       "        -3.09377816e-02, -9.52288415e-03,  4.03511152e-02, -3.51577662e-02,\n",
       "        -4.35719080e-02,  1.54986640e-03,  2.40377672e-02, -1.07403351e-02,\n",
       "        -2.14404594e-02, -3.50492597e-02, -6.07149862e-02,  5.72839659e-03,\n",
       "        -2.99396478e-02, -9.97088035e-04,  1.78252310e-02, -3.99326868e-02,\n",
       "        -4.67348509e-02,  1.17538562e-02,  6.69429358e-03,  1.21372249e-02,\n",
       "         2.07599662e-02,  7.66245555e-03,  3.38401739e-03, -4.85173576e-02,\n",
       "         5.47078140e-02, -1.01764277e-02, -4.31973971e-02,  2.08104076e-03,\n",
       "         4.48220931e-02, -3.24081928e-02,  2.62965336e-02, -2.22246870e-02,\n",
       "        -1.57361594e-03, -3.87509875e-02, -2.12445240e-02, -2.06598938e-02,\n",
       "        -7.92945735e-03, -5.09926341e-02,  1.86652150e-02, -7.98922703e-02,\n",
       "        -9.26914066e-03, -8.15474316e-02, -7.10685551e-03,  6.17293380e-02,\n",
       "         5.66983074e-02, -6.17757766e-03, -8.92665610e-02, -2.18616556e-02,\n",
       "        -1.76050905e-02,  2.18748748e-02,  5.68496026e-02, -4.83408803e-03,\n",
       "         2.70048268e-02,  1.00954607e-01,  1.54861789e-02,  4.39982414e-02,\n",
       "         8.52172542e-03,  1.52394120e-02, -1.68982055e-02, -3.72863971e-02,\n",
       "        -4.72998284e-02, -4.71987203e-02, -1.83405634e-02,  6.12210222e-02,\n",
       "         4.89988141e-02,  2.21092608e-02, -4.09185849e-02,  2.38485355e-03,\n",
       "         1.40488837e-02, -3.85081815e-03,  2.97771897e-02, -1.06839630e-04],\n",
       "       dtype=float32),\n",
       " array([ 1.73234027e-02, -1.32769002e-02, -2.42703408e-02,  3.84329632e-02,\n",
       "         1.08081596e-02, -5.86464405e-02,  2.29126029e-02,  6.74869046e-02,\n",
       "         4.06084396e-02,  1.29936042e-03,  4.29866090e-03, -2.49144738e-03,\n",
       "        -5.68564199e-02, -2.10358221e-02,  3.03447861e-02, -1.62468012e-02,\n",
       "         2.49861125e-02, -4.18760069e-03, -1.45019414e-02, -1.03967767e-02,\n",
       "         1.44381970e-02,  9.27796215e-03,  3.10424771e-02, -2.87955184e-03,\n",
       "         1.45214256e-02,  3.06813642e-02, -6.94430843e-02,  4.24876297e-03,\n",
       "         2.95645241e-02, -3.61430682e-02,  9.63677559e-03,  1.62329171e-02,\n",
       "         2.33893897e-02,  1.11387772e-02,  4.35179286e-03,  2.09863228e-03,\n",
       "         7.63552845e-04,  8.88350885e-03,  2.59088050e-03, -1.11683160e-01,\n",
       "        -2.35922467e-02, -2.17379071e-03, -1.86665487e-02,  2.37778313e-02,\n",
       "        -1.48263983e-02, -2.55657453e-02, -2.96970387e-03, -8.63732770e-03,\n",
       "         7.52160186e-03, -1.19852126e-02,  3.99882719e-03, -1.12455441e-02,\n",
       "        -7.14541879e-03, -3.29842754e-02, -2.20873789e-03, -9.74040944e-04,\n",
       "        -1.50437737e-02,  1.07569154e-02,  1.24463597e-02,  2.42400430e-02,\n",
       "         8.47497431e-04,  3.10168078e-04, -3.65616730e-03, -1.26145650e-02,\n",
       "         9.12839361e-03, -1.73662510e-03, -2.20066719e-02,  1.32873170e-02,\n",
       "        -1.30774537e-02,  3.81290703e-03, -2.49434579e-02,  9.97181144e-03,\n",
       "         2.33864207e-02, -4.63881250e-03, -4.80178394e-04,  1.14333034e-02,\n",
       "        -5.71471697e-04, -1.58871133e-02, -6.70712208e-03, -7.78361559e-02,\n",
       "        -2.13615503e-02, -3.01873870e-02,  3.11302813e-03,  3.90018895e-02,\n",
       "        -2.02592444e-02,  4.29197177e-02,  1.76693443e-02, -1.85818058e-02,\n",
       "         2.14765985e-02, -1.23278005e-02, -2.82176938e-02, -1.10759959e-02,\n",
       "        -7.43468285e-01,  3.14509161e-02,  7.19555747e-03, -5.90758817e-03,\n",
       "         1.93706173e-02, -1.50000295e-02, -9.10295988e-04, -3.01336888e-02,\n",
       "         1.69085823e-02, -2.04979740e-02,  2.76833232e-02,  4.59233671e-03,\n",
       "         4.31412570e-02,  8.78553092e-03, -2.39554524e-01,  5.29540330e-03,\n",
       "         2.03203019e-02,  1.23221166e-02, -2.91762082e-03, -5.68720885e-02,\n",
       "        -3.19049209e-02, -2.09228378e-02, -1.45951249e-02,  4.48057544e-04,\n",
       "        -1.16885221e-02, -8.78880452e-03,  4.10809321e-03, -7.82862119e-03,\n",
       "        -1.45864794e-02,  4.38219756e-02, -1.50582911e-02,  2.41901409e-02,\n",
       "         1.22709544e-02, -3.96705838e-03, -2.51476131e-02,  1.21564576e-02,\n",
       "        -6.43817242e-03, -1.45540833e-02,  4.50946242e-02, -7.51874084e-03,\n",
       "         7.71587389e-03,  9.15406868e-02,  7.54818600e-03,  5.00939274e-03,\n",
       "         1.58454906e-02, -3.63432728e-02, -2.68157478e-02,  8.72429647e-03,\n",
       "        -2.07258370e-02, -5.39550409e-02,  5.42285107e-03,  6.14290452e-03,\n",
       "        -1.72426421e-02,  4.78927017e-04, -1.68989338e-02,  2.36722920e-02,\n",
       "        -2.18696892e-03, -4.45315950e-02,  2.08612606e-02, -1.99679192e-02,\n",
       "         3.94839905e-02, -2.14489792e-02, -9.52541549e-03, -3.73376571e-02,\n",
       "        -2.15380788e-02, -3.08289588e-03,  2.03903820e-02,  1.03682019e-02,\n",
       "         3.12500894e-02, -2.77676340e-03, -3.53350192e-02, -4.32231985e-02,\n",
       "         3.00411787e-02, -1.65646861e-03,  2.29014247e-03,  1.91441476e-02,\n",
       "        -4.28955536e-03,  2.16600262e-02, -4.32142764e-02, -6.89827977e-03,\n",
       "        -1.11628361e-02, -1.96520169e-03, -1.10079441e-02, -2.72619631e-02,\n",
       "        -1.12970090e-02, -2.41885092e-02,  6.89322650e-02,  3.27076018e-02,\n",
       "        -1.93930301e-03, -2.95470823e-02, -1.56383999e-02, -4.19403985e-03,\n",
       "        -2.04446120e-03, -4.19643754e-03,  2.13772524e-02, -1.34302853e-02,\n",
       "         4.95350221e-04,  4.79385862e-03,  3.11526414e-02,  1.97138153e-02,\n",
       "         2.88089039e-03, -1.05170824e-03, -1.24167567e-02,  8.07113852e-03,\n",
       "         7.96767045e-03,  2.40297988e-02,  3.71446786e-03, -1.15447488e-04,\n",
       "         4.92546596e-02, -3.15253995e-02, -1.10915694e-02,  7.95880915e-04,\n",
       "        -1.83758438e-02,  2.00046729e-02,  9.84599697e-04,  1.93867739e-02,\n",
       "         2.25410312e-02,  2.24837638e-03,  4.23468603e-03,  5.64086661e-02,\n",
       "         2.33497042e-02, -1.87314060e-02, -8.62109289e-03,  2.65889857e-02,\n",
       "        -1.05799073e-02,  2.91583482e-02,  9.80669912e-03, -6.76939124e-03,\n",
       "         5.22445962e-02,  6.66230731e-03,  7.86666479e-03,  2.66831163e-02,\n",
       "         1.46752028e-02, -6.56916294e-03,  7.19964411e-03, -3.80559429e-03,\n",
       "         1.50154224e-02,  4.48516272e-02,  7.43431738e-03, -2.11686697e-02,\n",
       "         1.61456447e-02, -5.26765659e-02,  8.93956143e-03, -1.68019533e-02,\n",
       "        -8.72700382e-03, -4.63085696e-02, -5.35119278e-03,  1.23415925e-02,\n",
       "         1.17042577e-02,  5.26784034e-03,  2.85609141e-02,  2.26702006e-03,\n",
       "        -4.53217179e-02,  3.33809294e-02,  2.28391401e-02,  9.03761480e-03,\n",
       "        -1.19447038e-02, -1.47218443e-02, -1.34710977e-02, -3.54388058e-02,\n",
       "         4.51713502e-02, -2.35706437e-02, -1.45591907e-02,  1.05669536e-02,\n",
       "         2.26197708e-02, -6.23550918e-03, -5.28013930e-02, -3.07214409e-02,\n",
       "         8.10630212e-04, -6.33500377e-03, -1.87179656e-03,  7.70981982e-02,\n",
       "        -7.50693493e-03,  1.21101355e-02, -3.94118987e-02,  2.54240129e-02,\n",
       "         2.71508992e-02,  2.65576914e-02,  2.80896854e-02,  7.18821306e-03,\n",
       "         1.32341348e-02, -2.24709250e-02, -1.02123693e-02,  1.63854025e-02,\n",
       "         6.47271099e-03, -2.27258448e-02,  4.47176881e-02, -7.65575375e-03,\n",
       "         2.94589102e-02,  3.06369141e-02, -1.38545046e-02,  1.78468283e-02,\n",
       "         1.14357779e-02,  3.02427616e-02, -4.81964573e-02, -1.08771408e-02,\n",
       "        -2.58972473e-03, -7.60375056e-03, -3.25113023e-03, -8.60514771e-03,\n",
       "        -4.54965839e-03, -4.65768651e-04, -7.54329842e-03,  6.66226670e-02,\n",
       "        -1.04685716e-01, -1.26701444e-02,  2.94668647e-03, -1.74584761e-02,\n",
       "        -7.90372211e-03, -4.42068353e-02, -2.97284834e-02,  4.13948223e-02,\n",
       "        -3.35627161e-02, -2.32571922e-02,  1.06733162e-02,  4.55171764e-02,\n",
       "         2.68479511e-02,  1.36055779e-02, -3.50507013e-02,  2.30056047e-02,\n",
       "         9.16134790e-02,  5.99744804e-02, -2.30844878e-02,  5.44097424e-02,\n",
       "        -4.06662608e-03,  1.93822198e-02, -4.92541380e-02, -2.40473822e-02,\n",
       "         2.83119865e-02,  3.37822177e-02, -2.43736766e-02,  1.22593688e-02,\n",
       "        -4.56869742e-03, -2.77118217e-02,  2.06844062e-02, -4.28982228e-02,\n",
       "         3.22351195e-02,  5.45084812e-02, -2.04529818e-02,  1.62302665e-02,\n",
       "         7.54607562e-03, -2.10342035e-02, -1.97170060e-02, -2.37409193e-02,\n",
       "         3.95005895e-03,  9.31583624e-03,  2.60739494e-02, -1.89505005e-03,\n",
       "         9.75741167e-03, -3.31626344e-03, -2.14964468e-02,  1.90838091e-02,\n",
       "        -1.38261411e-02, -1.24583002e-02,  1.58143416e-02, -5.40700648e-03,\n",
       "         6.34245388e-03,  1.28692882e-02,  3.43649574e-02,  2.28652209e-02,\n",
       "         3.27092446e-02, -2.92666424e-02,  2.44341977e-02,  2.21293531e-02,\n",
       "        -2.36847550e-02, -2.64882967e-02, -1.44470353e-02,  3.71305160e-02,\n",
       "        -8.02746695e-03, -8.07764102e-03,  2.00023092e-02, -8.36272072e-03,\n",
       "        -1.06923133e-01,  2.41233781e-02,  1.45965032e-02,  5.90559356e-02,\n",
       "         3.58874425e-02, -9.88143869e-03, -3.64121124e-02,  4.79859812e-03,\n",
       "        -1.19278161e-02,  9.97235999e-03,  2.57199053e-02, -3.79226878e-02,\n",
       "        -4.31579165e-02,  3.10494448e-03, -1.96157396e-02,  1.57716069e-02,\n",
       "        -5.21985814e-02, -3.88779677e-02,  1.18391532e-02, -1.94462053e-02,\n",
       "         1.04660532e-02,  4.37754281e-02,  1.10417707e-02, -1.83044691e-02,\n",
       "        -3.66855897e-02,  1.96483359e-02, -7.29205310e-02, -4.79355734e-03,\n",
       "         1.02031545e-03,  2.24661012e-03,  7.96706975e-03,  8.95651150e-03,\n",
       "         1.99719127e-02, -3.88572887e-02, -1.04435431e-02, -2.34200973e-02,\n",
       "        -7.41175516e-03,  5.01532666e-03,  7.73343351e-03, -3.10517568e-02,\n",
       "        -3.71028893e-02,  9.69723053e-03, -3.65896262e-02, -4.80165519e-03,\n",
       "         4.75269109e-02, -5.16861975e-02,  2.64497455e-02, -1.64460372e-02,\n",
       "         3.87516469e-02, -1.29164681e-02,  1.83947012e-02,  3.69979702e-02,\n",
       "        -4.10803519e-02, -2.40277238e-02,  5.00604045e-03, -4.72482294e-02,\n",
       "        -2.73882248e-03, -1.15774442e-02,  5.92238549e-03, -4.60090414e-02,\n",
       "         1.39353815e-02,  5.31011210e-05,  2.32697558e-02, -7.12190708e-03,\n",
       "        -1.80835754e-01, -1.08448416e-03, -8.43454385e-04,  3.09299608e-03,\n",
       "        -1.89810488e-02, -2.65244599e-02, -3.47997732e-02,  8.00168328e-03,\n",
       "         3.01174466e-02, -2.11426392e-02,  1.29353693e-02, -2.72495337e-02,\n",
       "        -1.13433627e-02, -3.14717903e-03, -3.16662341e-02, -1.39419816e-03,\n",
       "        -4.65529524e-02,  1.83134992e-02,  2.15279330e-02, -1.44490507e-02,\n",
       "        -3.21001699e-03, -2.71646958e-03, -7.53624365e-03, -2.65845414e-02,\n",
       "        -2.59253271e-02, -3.15151401e-02, -8.08557309e-03,  1.08348122e-02,\n",
       "        -1.01363622e-02,  1.22825138e-03, -9.38909966e-03,  1.23432819e-02,\n",
       "         1.68227940e-03,  2.40754951e-02, -2.46718321e-02, -2.05101464e-02,\n",
       "         1.39257424e-02,  3.34401336e-03,  5.49226366e-02, -8.18423461e-03,\n",
       "         2.73219254e-02, -2.60804407e-02,  1.48731666e-02, -2.81532090e-02,\n",
       "         2.28354391e-02, -1.25428624e-02, -4.04228922e-03, -4.06169593e-02,\n",
       "         8.03133380e-03, -2.05622371e-02, -1.60063170e-02, -2.82644778e-02,\n",
       "        -9.02634766e-03,  1.38345156e-02, -5.33892773e-03,  3.65107059e-02,\n",
       "         6.47845212e-03, -3.67799923e-02, -1.13036279e-02,  1.25495037e-02,\n",
       "        -4.16554064e-02, -3.91954072e-02,  5.28057991e-03, -1.27066430e-02,\n",
       "         7.78122246e-03, -2.29799505e-02, -2.66523240e-03,  1.35377301e-02,\n",
       "        -5.03080860e-02,  9.08675883e-03,  1.50721045e-02, -2.35492047e-02,\n",
       "        -1.67366564e-02,  1.29969409e-02,  1.84124652e-02,  3.33820377e-03,\n",
       "        -2.81120278e-02, -2.47434340e-02, -3.17212939e-03,  3.42064165e-02,\n",
       "         9.67474841e-03,  8.99405032e-02, -2.72151595e-03,  3.25304121e-02],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018776b2-2608-421d-ab3f-fea4ee8e2685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:04.525599Z",
     "iopub.status.busy": "2025-09-28T22:10:04.525599Z",
     "iopub.status.idle": "2025-09-28T22:10:04.556707Z",
     "shell.execute_reply": "2025-09-28T22:10:04.554692Z",
     "shell.execute_reply.started": "2025-09-28T22:10:04.525599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'type': 'text'}, page_content='Annual Revenue Overview\\nThis document summarizes the revenue trends across Q1, Q2, and Q3. As illustrated in the chart\\nbelow, revenue grew steadily with the highest growth recorded in Q3.\\nQ1 showed a moderate increase in revenue as new product lines were introduced. Q2 outperformed\\nQ1 due to marketing campaigns. Q3 had exponential growth due to global expansion.'),\n",
       " Document(metadata={'page': 0, 'type': 'image', 'image_id': 'page_0_img_0'}, page_content='[Image: page_0_img_0]')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b872a563-b544-4037-99a6-cbfba5e6285e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:04.574172Z",
     "iopub.status.busy": "2025-09-28T22:10:04.568285Z",
     "iopub.status.idle": "2025-09-28T22:10:04.588523Z",
     "shell.execute_reply": "2025-09-28T22:10:04.588523Z",
     "shell.execute_reply.started": "2025-09-28T22:10:04.574172Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert embedding into numpy array\n",
    "\n",
    "embeddings_array = np.array(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93ee839-683c-46ac-8b82-76fa9304e6de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:04.604830Z",
     "iopub.status.busy": "2025-09-28T22:10:04.602134Z",
     "iopub.status.idle": "2025-09-28T22:10:04.623600Z",
     "shell.execute_reply": "2025-09-28T22:10:04.623600Z",
     "shell.execute_reply.started": "2025-09-28T22:10:04.604830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00267244,  0.01283   , -0.05183141, ..., -0.00385082,\n",
       "         0.02977719, -0.00010684],\n",
       "       [ 0.0173234 , -0.0132769 , -0.02427034, ...,  0.0899405 ,\n",
       "        -0.00272152,  0.03253041]], shape=(2, 512), dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "643ac50a-f240-48fa-84b2-c08333c73025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:04.633133Z",
     "iopub.status.busy": "2025-09-28T22:10:04.623600Z",
     "iopub.status.idle": "2025-09-28T22:10:04.650828Z",
     "shell.execute_reply": "2025-09-28T22:10:04.648739Z",
     "shell.execute_reply.started": "2025-09-28T22:10:04.633133Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let make a vector store we will use FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0070ef1-acce-425f-8185-fa38c6ca5050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:04.654939Z",
     "iopub.status.busy": "2025-09-28T22:10:04.652918Z",
     "iopub.status.idle": "2025-09-28T22:10:05.487102Z",
     "shell.execute_reply": "2025-09-28T22:10:05.485092Z",
     "shell.execute_reply.started": "2025-09-28T22:10:04.654939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "vector_store = FAISS.from_embeddings(\n",
    "    text_embeddings=[(doc.page_content, emb) for doc, emb in zip(all_docs , embeddings_array)],\n",
    "    embedding=None,\n",
    "    metadatas=[doc.metadata for doc in all_docs]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80619d6d-8a21-4e88-aa5b-472421859eb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:05.489911Z",
     "iopub.status.busy": "2025-09-28T22:10:05.487102Z",
     "iopub.status.idle": "2025-09-28T22:10:05.522253Z",
     "shell.execute_reply": "2025-09-28T22:10:05.518218Z",
     "shell.execute_reply.started": "2025-09-28T22:10:05.489911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x25d3128d290>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36dafdf2-3d51-455d-a679-665e33e6c5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:05.531322Z",
     "iopub.status.busy": "2025-09-28T22:10:05.525280Z",
     "iopub.status.idle": "2025-09-28T22:10:05.550021Z",
     "shell.execute_reply": "2025-09-28T22:10:05.543889Z",
     "shell.execute_reply.started": "2025-09-28T22:10:05.531322Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets initialize our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0de6902a-5089-4c83-9680-e7d5245976a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:05.558438Z",
     "iopub.status.busy": "2025-09-28T22:10:05.556418Z",
     "iopub.status.idle": "2025-09-28T22:10:11.424739Z",
     "shell.execute_reply": "2025-09-28T22:10:11.423224Z",
     "shell.execute_reply.started": "2025-09-28T22:10:05.558438Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca28098a-cf9a-40e8-bb2d-6574a34d4dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:11.431956Z",
     "iopub.status.busy": "2025-09-28T22:10:11.427986Z",
     "iopub.status.idle": "2025-09-28T22:10:11.455312Z",
     "shell.execute_reply": "2025-09-28T22:10:11.453290Z",
     "shell.execute_reply.started": "2025-09-28T22:10:11.431956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025D4DF83ED0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025D4E091390>, root_client=<openai.OpenAI object at 0x0000025D4DB8AE50>, root_async_client=<openai.AsyncOpenAI object at 0x0000025D4E091090>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20006310-d9dc-4433-b645-75bf1d37c029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:11.467265Z",
     "iopub.status.busy": "2025-09-28T22:10:11.457332Z",
     "iopub.status.idle": "2025-09-28T22:10:11.488616Z",
     "shell.execute_reply": "2025-09-28T22:10:11.483733Z",
     "shell.execute_reply.started": "2025-09-28T22:10:11.467265Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_multimodal(query , k=5):\n",
    "    query_embedding = embed_text(query)\n",
    "\n",
    "    results = vector_store.similarity_search_by_vector(embedding= query_embedding , k=k)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c34c41e-85a1-4fd2-be13-b77499afc1a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:11.499636Z",
     "iopub.status.busy": "2025-09-28T22:10:11.492650Z",
     "iopub.status.idle": "2025-09-28T22:10:11.510727Z",
     "shell.execute_reply": "2025-09-28T22:10:11.507964Z",
     "shell.execute_reply.started": "2025-09-28T22:10:11.499636Z"
    }
   },
   "outputs": [],
   "source": [
    "#Here is the formating of the query which will later will be given to the model (GPT-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45f589e3-62f7-44b1-b64c-0ae8bdac5ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:11.514759Z",
     "iopub.status.busy": "2025-09-28T22:10:11.514759Z",
     "iopub.status.idle": "2025-09-28T22:10:11.546550Z",
     "shell.execute_reply": "2025-09-28T22:10:11.542506Z",
     "shell.execute_reply.started": "2025-09-28T22:10:11.514759Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_multimodal_message(query , retrieved_docs):\n",
    "    content= []\n",
    "\n",
    "    #Well this is the first step when query comes, we just need to add raw query\n",
    "\n",
    "    content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\" : f\"The Question is: {query} \\n \\n Context \\n\"\n",
    "    })\n",
    "\n",
    "    #Now lets separate the text and image from documents\n",
    "    text_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"text\"]\n",
    "    image_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"image\"]\n",
    "    if temp_doc:\n",
    "        text_content = \"\\n\\n\".join([f\"[The page is: {doc.metadata['page']}]: {doc.page_content}\" for doc in text_docs])\n",
    "        content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\" : f\"The text Excrept:\\n {text_content}\\n\"\n",
    "        })\n",
    "\n",
    "    #Lets do it for the images\n",
    "    for doc in image_docs:\n",
    "        image_id = doc.metadata.get(\"image_id\")\n",
    "        if image_id and image_id in image_data_store:\n",
    "            content.append({\n",
    "                \"type\":\"text\",\n",
    "                \"text\": f\"\\n [The image data is from page {doc.metadata['page']}]: \\n\"\n",
    "            })\n",
    "            content.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{image_data_store[image_id]}\"\n",
    "                }\n",
    "            })\n",
    "\n",
    "    content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"\\n\\nPlease answer the question based on the provided text and images.\"\n",
    "    })\n",
    "\n",
    "    return HumanMessage(content=content)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59c5af2e-bf11-48b8-ab95-45a1ed5a9755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:11.548570Z",
     "iopub.status.busy": "2025-09-28T22:10:11.548570Z",
     "iopub.status.idle": "2025-09-28T22:10:11.569347Z",
     "shell.execute_reply": "2025-09-28T22:10:11.567329Z",
     "shell.execute_reply.started": "2025-09-28T22:10:11.548570Z"
    }
   },
   "outputs": [],
   "source": [
    "def multimodal_pdf_rag_pipeline(query):\n",
    "    context_docs = retrieve_multimodal(query , k =4)\n",
    "    message = create_multimodal_message(query , context_docs)\n",
    "    response = llm.invoke([message])\n",
    "\n",
    "    #Print retrieved context info \n",
    "    print(f\"\\n Retrieved {len(context_docs)} documents: \")\n",
    "\n",
    "    for doc in context_docs:\n",
    "        doc_type = doc.metadata.get(\"type\" , \"unknown\")\n",
    "        page = doc.metadata.get(\"page\" , \"?\")\n",
    "\n",
    "        if doc_type == \"text\":\n",
    "            preview = doc.page_content[:100] + \"...\" if len(doc.page_content) > 100 else doc.page_content\n",
    "            print(f\"  - Text from page {page} : {preview}\")\n",
    "        else:\n",
    "            print(f\"  - Image is from page {page}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return response.content\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92c92fd9-ed91-4725-93ec-5a8df75828de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:10:11.569347Z",
     "iopub.status.busy": "2025-09-28T22:10:11.569347Z",
     "iopub.status.idle": "2025-09-28T22:10:17.701453Z",
     "shell.execute_reply": "2025-09-28T22:10:17.701453Z",
     "shell.execute_reply.started": "2025-09-28T22:10:11.569347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Query: Summarize the main findings from the document\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m answer = \u001b[43mmultimodal_pdf_rag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mmultimodal_pdf_rag_pipeline\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      2\u001b[39m context_docs = retrieve_multimodal(query , k =\u001b[32m4\u001b[39m)\n\u001b[32m      3\u001b[39m message = create_multimodal_message(query , context_docs)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#Print retrieved context info \u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Retrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(context_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents: \u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1184\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1183\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1187\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1188\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1189\u001b[39m ):\n\u001b[32m   1190\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1179\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1172\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1173\u001b[39m             response,\n\u001b[32m   1174\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1175\u001b[39m             metadata=generation_info,\n\u001b[32m   1176\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1177\u001b[39m         )\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1179\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m         response = raw_response.parse()\n\u001b[32m   1181\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\med\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    queries = [\n",
    "        \"Summarize the main findings from the document\"\n",
    "    ]\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"\\n Query: {query}\")\n",
    "        print(\"-\" * 50)\n",
    "        answer = multimodal_pdf_rag_pipeline(query)\n",
    "        print(f\"Answer: \\n {answer}\")\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71178715-f8ed-43f9-8f7d-d70643aba045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
